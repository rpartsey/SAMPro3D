{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils.vis_utils import show_mask_ins, show_points_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "# dataset params\n",
    "dataset_dir = \"/home/rpartsey/code/eai/SAMPro3D-fork/data/scannet/scans\"\n",
    "scene_name = \"scene0000_02\"\n",
    "model = \"sam\"\n",
    "# scene_name = \"scene0008_00\"\n",
    "# scene_name = \"scene0013_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment params\n",
    "# experiments_dir = \"/home/rpartsey/code/eai/SAMPro3D-fork/experiments/scannet/scans/3js_prompt\"\n",
    "experiments_dir = \"/home/kuzhum/sam/SAMPro3D/experiments\"\n",
    "# experiment_name = \"guitar\"\n",
    "\n",
    "prompt_path = f\"{dataset_dir}/{scene_name}/{scene_name}_guitar.ply\"\n",
    "# sam_output_path =  f\"{experiments_dir}/{scene_name}/{experiment_name}/sam_output\"\n",
    "# sampro3d_predictions =  f\"{experiments_dir}/{scene_name}/{experiment_name}/sampro3d_predictions\"\n",
    "# output_vis_path = f\"{experiments_dir}/{scene_name}/{experiment_name}/visualization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object names: ['guitar_sam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6171/6171 [00:21<00:00, 285.17it/s][ WARN:0@7410.506] global loadsave.cpp:241 findDecoder imread_('/home/rpartsey/code/eai/SAMPro3D-fork/data/scannet/scans/scene0000_02/color/6170.jpg'): can't open/read file: check file path/integrity\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 6170 not found at /home/rpartsey/code/eai/SAMPro3D-fork/data/scannet/scans/scene0000_02/color/6170.jpg\n",
      "Video saved to scene0000_02_sam.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your dataset and experiment directories\n",
    "# dataset_dir = 'path_to_dataset_dir'       # Replace with your dataset directory\n",
    "# experiments_dir = 'path_to_experiments_dir'  # Replace with your experiments directory\n",
    "# scene_name = 'scene_name'                   # Replace with your scene name\n",
    "\n",
    "# Generate random colors for each object\n",
    "colors = [np.random.randint(0, 256, 3).tolist() for _ in range(1000)]  # BGR format\n",
    "object_names = [name for name in os.listdir(f\"{experiments_dir}/{scene_name}\") if name.endswith(model)]\n",
    "print(f\"Object names: {object_names}\")\n",
    "\n",
    "def show_mask_ins(mask, frame, color):\n",
    "    # print(mask)\n",
    "    # Create a color mask where the mask is True\n",
    "    color_mask = frame.copy()\n",
    "    color_mask[mask > 0] = color\n",
    "\n",
    "    # Blend the color mask with the frame\n",
    "    alpha = 0.5  # Transparency factor\n",
    "    frame = cv2.addWeighted(frame, 1 - alpha, color_mask, alpha, 0)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def show_points_color(points, frame, color, marker_size=5):\n",
    "    for coord in points:\n",
    "        x, y = int(coord[0]), int(coord[1])\n",
    "        cv2.circle(frame, (x, y), marker_size, color, -1)  # Filled circle\n",
    "    return frame\n",
    "\n",
    "def create_visualization_video_with_opencv(start_frame_idx, end_frame_idx, output_video_path, fps=30, frame_size=(1920, 1080)):\n",
    "    # Define the codec and initialize the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec if needed\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
    "\n",
    "    for i in tqdm(range(start_frame_idx, end_frame_idx + 1)):\n",
    "        frame_path = f\"{dataset_dir}/{scene_name}/color/{i}.jpg\"\n",
    "        frame = cv2.imread(frame_path)\n",
    "\n",
    "        if frame is None:\n",
    "            print(f\"Frame {i} not found at {frame_path}\")\n",
    "            continue\n",
    "\n",
    "        original_height, original_width = frame.shape[:2]\n",
    "\n",
    "        # Resize frame to desired size if necessary\n",
    "        if (original_width, original_height) != frame_size:\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "\n",
    "        for j, object_name in enumerate(object_names):\n",
    "            sam_output_path = f\"{experiments_dir}/{scene_name}/{object_name}/sam_output\"\n",
    "            mask_path = f\"{sam_output_path}/masks_npy/{i}.npy\"\n",
    "            points_path = f\"{sam_output_path}/points_npy/{i}.npy\"\n",
    "\n",
    "            # Overlay mask if it exists\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = np.load(mask_path)\n",
    "                \n",
    "                if model == \"sam2\":\n",
    "                    mask = mask.reshape(-1, 480, 640)\n",
    "\n",
    "                if mask is None or mask.size == 0:\n",
    "                    print(f\"Mask at {mask_path} is empty or invalid.\")\n",
    "                    continue\n",
    "\n",
    "                # **Squeeze the mask to remove singleton dimensions**\n",
    "                mask = np.squeeze(mask)\n",
    "\n",
    "                # # Ensure mask is 2D\n",
    "                # if mask.ndim != 2:\n",
    "                #     print(f\"Mask at {mask_path} is not 2D after squeezing.\")\n",
    "                #     continue\n",
    "\n",
    "                # # Convert mask to uint8 if necessary\n",
    "                # if mask.dtype != np.uint8:\n",
    "                #     mask = mask.astype(np.uint8)\n",
    "\n",
    "                # Resize mask to match frame size if necessary\n",
    "                if mask.shape != (frame_size[1], frame_size[0]):\n",
    "                    if frame_size[0] > 0 and frame_size[1] > 0:\n",
    "                        mask = cv2.resize(mask, (frame_size[0], frame_size[1]), interpolation=cv2.INTER_NEAREST)\n",
    "                    else:\n",
    "                        print(f\"Invalid frame size: {frame_size}\")\n",
    "                        continue\n",
    "\n",
    "                frame = show_mask_ins(mask, frame, colors[j])\n",
    "\n",
    "            # Draw points if they exist\n",
    "            if os.path.exists(points_path):\n",
    "                points = np.load(points_path)\n",
    "\n",
    "                # Adjust points if frame size changed\n",
    "                if (original_width, original_height) != frame_size:\n",
    "                    scale_x = frame_size[0] / original_width\n",
    "                    scale_y = frame_size[1] / original_height\n",
    "                    points[:, 0] = points[:, 0] * scale_x\n",
    "                    points[:, 1] = points[:, 1] * scale_y\n",
    "\n",
    "                frame = show_points_color(points, frame, colors[j], marker_size=5)\n",
    "\n",
    "        # Write the processed frame to the video\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    # Release the video writer\n",
    "    video_writer.release()\n",
    "    print(f\"Video saved to {output_video_path}\")\n",
    "\n",
    "# Get number of frames in the scene\n",
    "num_frames = len(os.listdir(f\"{dataset_dir}/{scene_name}/color\"))\n",
    "\n",
    "# Example usage\n",
    "create_visualization_video_with_opencv(\n",
    "    start_frame_idx=0,\n",
    "    end_frame_idx=num_frames,\n",
    "    output_video_path=f'{scene_name}_{model}.mp4',\n",
    "    frame_size=(640, 480)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 772\n",
    "frame_path = f\"{dataset_dir}/{scene_name}/color/{i}.jpg\"\n",
    "frame = Image.open(frame_path)\n",
    "frame.show()\n",
    "\n",
    "\n",
    "mask_path = f\"{sam_output_path}/masks_npy/{i}.npy\"\n",
    "mask = np.load(mask_path)\n",
    "print(mask.shape)\n",
    "\n",
    "points_path = f\"{sam_output_path}/points_npy/{i}.npy\"\n",
    "points = np.load(points_path)\n",
    "print(points.shape)\n",
    "\n",
    "\n",
    "def visualize_masks_and_points(frame, points):\n",
    "    \"\"\"\n",
    "    Visualize masks and points on the given frame for specified mask indices.\n",
    "    \n",
    "    Args:\n",
    "    frame (PIL.Image): The input image\n",
    "    mask (np.array): Array of masks\n",
    "    points (np.array): Array of points\n",
    "    start_idx (int): Starting index of masks to visualize\n",
    "    end_idx (int): Ending index of masks to visualize\n",
    "    \"\"\"\n",
    "    # Convert PIL Image to numpy array\n",
    "    frame_np = np.array(frame)\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Display the frame\n",
    "    ax.imshow(frame_np)\n",
    "    \n",
    "    # Plot masks and points\n",
    "    show_points_color(points, np.ones(points.shape[0]), ax, np.random.rand(3), marker_size=200)\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "start_idx = 0\n",
    "end_idx = 2  # Visualize first 5 masks and points\n",
    "visualize_masks_and_points(frame, points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sampro3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
